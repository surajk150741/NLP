{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After tokenizer, we need three tensors:\n",
    "- input_ids.\n",
    "- attention_mask.\n",
    "- labels.(for now, the label tensor would be the input_ids) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- now, input_ids needs to be passed through a masked language modelling script. Which will mask around 15% of the tokens withing that tensor.\n",
    "- while training, model is essentially going to try and guess what those masked tokens are. then optimize the model using the loss between the guesses that the model outputs from the input ids and real values(i.e our labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MLM\n",
    "MLM is one of the two core training approaches. Another one being next sentence prediction.\n",
    "- Masking is a way to tell sequence-processing layers that certain timesteps in an input are missing, and thus should be skipped when processing the data.\n",
    "- We will mask around 15% of the tokens.\n",
    "- So we’re actually inputting an incomplete sentence and asking BERT to complete it for us.\n",
    "- Example being humans learning fill in the blanks. As humans, we use a mix of general world knowledge, and linguistic understanding to come to that conclusion. For BERT, this guess will come from reading a lot — and learning linguistic patterns incredibly well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Argmax is an operation that finds the argument that gives the maximum value from a target function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "labels == input_ids\n",
    "\n",
    "input_ids -> MLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we initialize out tokenizer and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "text = (\"After my milk, I will eat the banana\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "return_tensors (str or TensorType, optional) –\n",
    "\n",
    "If set, will return tensors instead of list of python integers. Acceptable values are:\n",
    "\n",
    "'tf': Return TensorFlow tf.constant objects.\n",
    "\n",
    "'pt': Return PyTorch torch.Tensor objects.\n",
    "\n",
    "'np': Return Numpy np.ndarray objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# then we tokenize the text:\n",
    "\n",
    "inputs = tokenizer(text, return_tensors='pt')\n",
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  2044,  2026,  6501,  1010,  1045,  2097,  4521,  1996, 15212,\n",
       "           102]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.input_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "101 is CLS, 103 is mask token. 102 is seperator token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now, we can go ahead and create our target labels\n",
    "and target labels needs to be contained in within a tensor called labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# it just needs to be a copy of this input ids tensor\n",
    "inputs['labels'] = inputs.input_ids.detach().clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2044,  2026,  6501,  1010,  1045,  2097,  4521,  1996, 15212,\n",
       "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'labels': tensor([[  101,  2044,  2026,  6501,  1010,  1045,  2097,  4521,  1996, 15212,\n",
       "           102]])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next, we want to mask a random number of input ids or tokens within the input ids tensor, but not the labels tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 11])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize input tokens here we create a random array of floats within dimension equal to input_ids tensor\n",
    "rand = torch.rand(inputs.input_ids.shape)\n",
    "rand.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1942, 0.8076, 0.0601, 0.0249, 0.3020, 0.9449, 0.3641, 0.6106, 0.7794,\n",
       "         0.3370, 0.3545]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now, if we want to select random 15% of those "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False,  True,  True, False, False, False, False, False, False,\n",
       "         False]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_arr = (rand<0.15)*(inputs.input_ids != 101) * (inputs.input_ids != 102)\n",
    "mask_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we see above that our classifier token is masked, we don't want that\n",
    "so we are going to add a little logic "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we add the filter below in above cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         False]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(inputs.input_ids != 101) * (inputs.input_ids != 102)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now, i want the index positions of these True values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nonzero gives vector with indeces having true values and then convert it into a list\n",
    "selection = torch.flatten(mask_arr[0].nonzero()).tolist()\n",
    "selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flattens input by reshaping it into a one-dimensional tensor. If start_dim or end_dim are passed, only dimensions starting with start_dim and ending with end_dim are flattened. The order of elements in input is unchanged.\n",
    "\n",
    "t = torch.tensor([[[1, 2],\n",
    "\n",
    "                   [3, 4]],\n",
    "\n",
    "                  [[5, 6],\n",
    "\n",
    "                   [7, 8]]])\n",
    "\n",
    "torch.flatten(t)\n",
    "\n",
    "torch.flatten(t, start_dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we use the selection to select a certain number or select those indices within our input ids tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  2044,   103,   103,  1010,  1045,  2097,  4521,  1996, 15212,\n",
       "           102]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.input_ids[0, selection] = 103\n",
    "inputs.input_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now, we can pass all this into our model and the model will calculate our loss on the logits that we saw before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['loss', 'logits'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.8697, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with this loss information, we can optimize our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
